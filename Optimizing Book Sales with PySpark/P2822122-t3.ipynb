{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93203cd1-772a-47b6-b2bf-7bdadd4bb9f9",
   "metadata": {},
   "source": [
    "# Spark Assignment Task 3\n",
    "\n",
    "## Big Data Systems\n",
    "\n",
    "---\n",
    "\n",
    "> Marianna Konstantopoulou <br />\n",
    "> MSc Business Analytics Part Time <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48da139-9ed9-4cb6-84a3-ac981ed3aac5",
   "metadata": {},
   "source": [
    "As a final task, your supervisor assigned to you to investigate if it is possible to train a linear regression model (using LinearRegression() function) that could predict the “average_rating” of a book, using as input, its “language_code”, its “num_pages”, its “ratings_count”, and its “publication year”. Again you should use Python and Dataframes, this time with MLlib. You should pay attention to transform the string-based input features (“language_code” and “publication_year”) using the proper representation format, and you should explain your choices. Your code should (a) prepare the feature vectors, (b) prepare the training and testing datasets (70%-30%), (c) train the model, and (d) evaluate the accuracy of the model (based on the Rsquared metric) and display the corresponding metric on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f589d3-078b-46d6-ae01-403bdc1f8029",
   "metadata": {},
   "source": [
    "## 1. Load the dataset and convert data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e1cd11ea-df29-4bb8-a5fb-81c6fdafc635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|          4.12|      Unknown|     null|            1|         Unknown|\n",
      "|          3.94|          fre|     null|           16|            2016|\n",
      "|          4.28|          eng|      146|           51|            2012|\n",
      "|          4.05|          eng|     null|            6|         Unknown|\n",
      "|          4.06|        en-US|      272|           51|            1997|\n",
      "|          3.44|      Unknown|      206|           46|            2007|\n",
      "|          4.15|          eng|      224|           39|            2016|\n",
      "|          3.16|      Unknown|      160|           38|            2016|\n",
      "|          3.51|      Unknown|      160|           44|            2016|\n",
      "|          4.00|      Unknown|      144|           32|            2016|\n",
      "|          4.41|          kor|      212|          133|            2014|\n",
      "|          3.16|          eng|      144|          114|            2011|\n",
      "|          4.41|          eng|      200|          149|            2012|\n",
      "|          4.39|      Unknown|      230|          152|            2012|\n",
      "|          1.86|      Unknown|     null|           64|         Unknown|\n",
      "|          4.31|          jpn|      157|          174|            2013|\n",
      "|          4.43|          spa|      224|           30|            2006|\n",
      "|          4.38|          zho|      176|            2|            2011|\n",
      "|          3.80|      Unknown|      192|           86|            2006|\n",
      "|          4.46|          eng|      192|            8|         Unknown|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#First we load the dataset\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"bookstore\").getOrCreate()\n",
    "\n",
    "dataset = spark.read.json(\"books_5000.json\")\n",
    "dataset = dataset.select('average_rating', 'language_code','num_pages', 'ratings_count','publication_year')\n",
    "from pyspark.sql.functions import col,when\n",
    "dataset = dataset.withColumn(\"language_code\", when(col(\"language_code\")==\"\" ,'Unknown').otherwise(col(\"language_code\")))\n",
    "dataset = dataset.withColumn(\"num_pages\", when(col(\"num_pages\")==\"\", None).otherwise(col(\"num_pages\")))\n",
    "dataset = dataset.withColumn(\"publication_year\", when(col(\"publication_year\")==\"\" ,'Unknown').otherwise(col(\"publication_year\")))\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84389a8-b937-458e-81cf-b1602343e72f",
   "metadata": {},
   "source": [
    "* As first step we amend the types of some columns that are in interest for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c388bcd1-1562-496b-b32d-847d39b797ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- num_pages: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- publication_year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fc329715-9fea-4ddc-88d0-a893d37ce0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average_rating', 'double'),\n",
       " ('language_code', 'string'),\n",
       " ('num_pages', 'int'),\n",
       " ('ratings_count', 'int'),\n",
       " ('publication_year', 'string')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "dataset = dataset.withColumn(\"num_pages\", dataset[\"num_pages\"].cast(IntegerType()))\n",
    "dataset = dataset.withColumn(\"average_rating\", dataset[\"average_rating\"].cast(DoubleType()))\n",
    "dataset = dataset.withColumn(\"ratings_count\", dataset[\"ratings_count\"].cast(IntegerType()))\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac17c1-f8f8-4809-93e4-ea326de4377e",
   "metadata": {},
   "source": [
    "* Then we will delete rows with NA in column `num_pages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "76657249-8843-469a-96b4-dde5b2e130a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|          4.28|          eng|      146|           51|            2012|\n",
      "|          4.06|        en-US|      272|           51|            1997|\n",
      "|          3.44|      Unknown|      206|           46|            2007|\n",
      "|          4.15|          eng|      224|           39|            2016|\n",
      "|          3.16|      Unknown|      160|           38|            2016|\n",
      "|          3.51|      Unknown|      160|           44|            2016|\n",
      "|           4.0|      Unknown|      144|           32|            2016|\n",
      "|          4.41|          kor|      212|          133|            2014|\n",
      "|          3.16|          eng|      144|          114|            2011|\n",
      "|          4.41|          eng|      200|          149|            2012|\n",
      "|          4.39|      Unknown|      230|          152|            2012|\n",
      "|          4.31|          jpn|      157|          174|            2013|\n",
      "|          4.43|          spa|      224|           30|            2006|\n",
      "|          4.38|          zho|      176|            2|            2011|\n",
      "|           3.8|      Unknown|      192|           86|            2006|\n",
      "|          4.46|          eng|      192|            8|         Unknown|\n",
      "|          4.25|          jpn|      183|           32|            2012|\n",
      "|          4.59|          ita|      192|           23|            2017|\n",
      "|           4.3|          eng|       52|          319|            2010|\n",
      "|          3.67|          nor|       80|           16|            2013|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.na.drop()\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223030d6-e026-43d0-90fb-74b1af9bfc63",
   "metadata": {},
   "source": [
    "## 2. Prepare data for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bb3ab8b1-7aba-482c-9389-172ace57501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2537\n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = dataset.randomSplit([0.7, 0.3], seed=42) #The Hitchhiker’s Guide to the Galaxy refference\n",
    "\n",
    "print(trainDF.cache().count()) # Cache because accessing training data multiple times\n",
    "\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc971b2-a278-4c6c-ad93-37512d803cd0",
   "metadata": {},
   "source": [
    "We decide to to a 70/30 split for train and test and we use `seed` so that for each run we have exactly the same split (for reproducibility). \n",
    "Finally, we use the cache() function to keep `trainDF` in memory for efficiency reasons, since the training dataset will be used multiple times during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9d4ebd29-a4cc-4e74-86f3-89ad35784d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|           2.0|      Unknown|      144|            1|            2017|\n",
      "|           2.0|          ind|      128|            1|            2010|\n",
      "|          2.29|      Unknown|      136|           82|            2016|\n",
      "|          2.33|      Unknown|      368|            3|            2002|\n",
      "|          2.35|      Unknown|      104|           43|            2008|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a05d5-267c-4c08-a545-f02e107b7aed",
   "metadata": {},
   "source": [
    "## 3. Feature preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c539b4-f44a-4152-811a-e5dae2de2006",
   "metadata": {},
   "source": [
    "Linear regression, requires numeric features. Our dataset includes categorical features such as `publication_year` and `language_code`. If we want to consider them, we need to manipulate or reprocess them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8ae2c-8371-4818-a523-69201c66ca32",
   "metadata": {},
   "source": [
    "We will use **one hot encoding**, that converts categorical variables into a set of numeric variables that only take on values 0 and 1. We will first use the `StringIndexer`, followed by the `OneHotEncoder` **estimator**.\n",
    "\n",
    "The following code block defines the `StringIndexer` and `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "749bfed9-a79f-4869-bdc4-9b9bd88f9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# We determine which of the columns are categorical.\n",
    "categoricalCols = [\"language_code\", \"publication_year\"]\n",
    "\n",
    "# The following two lines are estimators. They return functions that we will later apply to transform the dataset.\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + \"Index\" for x in categoricalCols]).setHandleInvalid(\"keep\")\n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categoricalCols]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d7e869-1b5f-4c38-af2e-839a1ab7ab10",
   "metadata": {},
   "source": [
    "Following that, we'll create a *pipeline* that combines all of our feature engineering and modeling phases to complete our task. But first, we will take a look at how estimators and transformers function by using the `StringIndexer` estimator from the preceding code block. We can use the `.fit()` function to get a `StringIndexerModel` which we can then utilize to alter the dataset.\n",
    "The `.transform()` method of `StringIndexerModel` returns a new DataFrame with the new columns appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0ad495c5-7ec0-4f85-bab0-457171203fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|language_codeIndex|publication_yearIndex|\n",
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "|           2.0|      Unknown|      144|            1|            2017|               1.0|                  9.0|\n",
      "|           2.0|          ind|      128|            1|            2010|               3.0|                  6.0|\n",
      "|          2.29|      Unknown|      136|           82|            2016|               1.0|                  1.0|\n",
      "|          2.33|      Unknown|      368|            3|            2002|               1.0|                 16.0|\n",
      "|          2.35|      Unknown|      104|           43|            2008|               1.0|                  8.0|\n",
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexerModel = stringIndexer.fit(trainDF)\n",
    "stringIndexerModel.transform(trainDF).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f06a4cf4-1f85-4325-9473-a5b3a82082c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = [\"num_pages\", \"ratings_count\"]\n",
    "assemblerInputs = [c + \"OHE\" for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\", handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41b53d-e0f6-4e82-9e08-793a4a827219",
   "metadata": {},
   "source": [
    "## 4. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ddad2405-b8d3-4265-8409-278892f82ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"average_rating\", regParam=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5b360-0edf-443a-9385-072a9e61612c",
   "metadata": {},
   "source": [
    "## 5. Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f1210002-9822-4efd-baf5-c94fabfa006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline based on the stages created in previous steps.\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, vecAssembler, lr])\n",
    "\n",
    "# Define the pipeline model.\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Apply the pipeline model to the test dataset to predict the average rating of a book.\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cee6dca2-02cf-41c2-9f03-abd6a38a7368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------+\n",
      "|            features|average_rating|        prediction|\n",
      "+--------------------+--------------+------------------+\n",
      "|(92,[1,39,90,91],...|          2.57|3.8868249903039183|\n",
      "|(92,[1,53,90,91],...|          2.67|3.8764447146221372|\n",
      "|(92,[7,42,90,91],...|          2.71|  3.88069845863319|\n",
      "|(92,[0,41,90,91],...|          2.72| 3.904210164925219|\n",
      "|(92,[1,70,90,91],...|          2.81|3.8340308856420102|\n",
      "+--------------------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select(\"features\", \"average_rating\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c2727-1780-4e4e-b9ef-45afbc4f4418",
   "metadata": {},
   "source": [
    "* We will evaluate the accuracy of the model (based on the Rsquared metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ae64cf94-dfa4-49e5-ba27-a8679b44ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.0512271\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"average_rating\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(predDF))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
